{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Recommendation Engines with PySpark\n",
    "PySpark를 활용한 추천 엔진 개발"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import\n",
    "---\n",
    "필요한 라이브러리 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyspark findspark wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import pyspark\n",
    "from pyspark.sql.functions import min, max, avg, col\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "findspark.init()\n",
    "spark = SparkSession.builder.appName('MovieLens').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset\n",
    "---\n",
    "데이터셋 다운로드 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget, os\n",
    "\n",
    "if not os.path.exists(\"./ml-20m.zip\"):\n",
    "    url = \"https://files.grouplens.org/datasets/movielens/ml-20m.zip\"\n",
    "    wget.download(url)\n",
    "else:\n",
    "    print(\".zip file already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파일 압축 풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "if not os.path.exists(\"./ml-20m\"):\n",
    "    with zipfile.ZipFile(\"ml-20m.zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall(\".\")\n",
    "else:\n",
    "    print(\".zip file already extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "---\n",
    "CSV 파일 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = spark.read.option(\"header\", \"true\").csv(\"ml-20m/ratings.csv\")\n",
    "movies = spark.read.option(\"header\", \"true\").csv(\"ml-20m/movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테이블 스키마"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Schema of ratings table:\")\n",
    "ratings.printSchema()\n",
    "ratings.show(5)\n",
    "\n",
    "print(\"Schema of movies table:\")\n",
    "movies.printSchema()\n",
    "movies.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Data sparsity 계산하기\n",
    "- User - Movie 행렬이 있을 때, 전체 원소 중 $(u, m)$ element가 empty인 비율\n",
    "- $\\text{sparsity} = \\frac{\\text{Num\\_ratings}}{\\text{Num\\_users}\\times\\text{Num\\_movies}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerator = number of ratings\n",
    "numerator = ratings.count()\n",
    "\n",
    "# denominator = number of users * number of movies\n",
    "num_users = ratings.select(\"userId\").distinct().count()\n",
    "num_movies = ratings.select(\"movieId\").distinct().count()\n",
    "\n",
    "print(f\"\"\"\n",
    "Number of users: {num_users},\n",
    "Number of movies: {num_movies}\n",
    "\"\"\")\n",
    "\n",
    "denominator = num_users * num_movies\n",
    "\n",
    "sparsity = 1 - numerator * 1. / denominator\n",
    "print(f\"Sparsity: {sparsity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupBy와 Aggregate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## User 별 평점 부여 횟수\n",
    "# ratings.groupBy(\"userId\").count().show()\n",
    "# ## User 중 가장 적은 평점 부여 횟수\n",
    "# ratings.groupBy(\"userId\").count().select(min(\"count\")).show()\n",
    "# ## User 중 가장 많은 평점 부여 횟수\n",
    "# ratings.groupBy(\"userId\").count().select(max(\"count\")).show()\n",
    "# ## User 당 평균 평점 부여 횟수\n",
    "# ratings.groupBy(\"userId\").count().select(avg(\"count\")).show()\n",
    "\n",
    "## 평점 부여 횟수가 20회 이상인 User들의 userId와 count\n",
    "# ratings.groupBy(\"userId\").count().filter(col(\"count\")>=20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = ratings.join(movies, \"movieId\", \"left\").select([\"movieId\", \"userId\", \"rating\"])\n",
    "\n",
    "movie_ratings = movie_ratings.select(movie_ratings.userId.cast(\"integer\"),\\\n",
    "    ratings.movieId.cast(\"integer\"),\\\n",
    "    ratings.rating.cast(\"double\"))\n",
    "(training_data, test_data) = movie_ratings.randomSplit([.8, .2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = ALS(userCol=\"userId\", \n",
    "            itemCol=\"movieId\", \n",
    "            ratingCol=\"rating\", \n",
    "            coldStartStrategy=\"drop\", \n",
    "            nonnegative=True, \n",
    "            implicitPrefs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [5, 40, 80, 120]\n",
    "maxIters = [5, 100, 250, 500]\n",
    "regParams = [.05, .1, 1.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "param_grid = ParamGridBuilder()\\\n",
    "    .addGrid(als.rank, ranks)\\\n",
    "    .addGrid(als.maxIter, maxIters)\\\n",
    "    .addGrid(als.regParam, regParams)\\\n",
    "    .build()\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "cv = CrossValidator(estimator = als,\n",
    "    estimatorParamMaps= param_grid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=5)\n",
    "\n",
    "model = cv.fit(training_data)\n",
    "\n",
    "best_model = model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.transform(test_data)\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"\"\"\n",
    "    ***Best Model***\n",
    "    RMSE = {rmse}\n",
    "    Rank: {best_model.rank}\n",
    "    MaxIter: {best_model._java_obj.parent().getMaxIter()}\n",
    "    RegParam: {best_model._java_obj.parent().getRegParam()}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
