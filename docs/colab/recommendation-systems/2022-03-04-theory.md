---
layout: post
title:  "추천 시스템"
parent: Recommendation Systems
grand_parent: ML/DL Practice
nav_order: 1
date:   2022-03-04 10:50:00 +0900
---
# Recommendation Systems
{: .no_toc }

<details open markdown="block">
  <summary>
    목차
  </summary>
  {: .text-delta }
1. TOC
{:toc}
</details>

## 개요
---
* 왜 추천 시스템이 필요한가?
* 추천 시스템을 구성하는 컴포넌트: Candidate generation, Scoring, and Re-ranking
* Item, Query, 그리고 Embedding
* Candidate generation에서 사용되는 기술에 대한 이해
* Matrix factorization과 Softmax를 구현

## Why recommendation?
---
추천이 필요한 이유
- 추천 엔진은 사용자에게 매력적인 컨텐츠를 사용자의 직접 검색 없이 제공한다
- 구글 플레이 스토어의 전체 앱 설치의 40%, YouTube 총 시청 시간의 60%가 추천에서 비롯되었다

추천 종류
1. Homepage recommendation: 사용자의 관심사를 기반으로 개인화 추천 (모든 사용자들은 각각 다른 추천을 제공받음)
2. Related item recommendation: 수학 앱을 찾는 유저에게 다른 수학 앱 또는 과학 앱을 추천

주요 용어
- Items (Documents): 추천 시스템이 추천하는 개체 (entity)
    - 구글 플레이 스토어의 경우 "설치 가능한 앱", YouTube의 경우 "영상"
- Query (Context): 추천을 하기 위해 시스템이 사용하는 정보
    - User 정보 (ID, 이전에 Interact한 Item)
    - 추가 Context (날짜 및 시간, 사용 기기)
- Embedding: 
    - Query set 또는 Recommended item set과 같은 Discrete set에서 
    - Vector space (Embeddeing space)로의 맵핑

추천 시스템 개요
1. Candidate generation
    - 대규모의 코퍼스가 주어졌을 때, 소규모의 subset of candidate을 생성한다
        - (Youtube의 candidate generator는 수십억개의 비디오를 수십만개로 줄인다)
    - 코퍼스의 규모를 고려하여 모델은 query를 evaluate한다
    - 여러 개의 generator를 활용하는 경우 각 generator는 서로 다른 candidate subset을 제공한다
2. Scoring
    - 사용자에게 보여줄 item set을 선택하기 위해, 모덿은 candidate을 scoring하고 ranking을 매긴다
    - 상대적으로 작은 item subset을 evaluate하므로, 시스템은 추가 query에 따라 더 정확한 모델을 활용할 수 있다.
3. Re-ranking
    - 최종 ranking을 구하기 위해 시스템은 추가적인 제약 조건을 고려한다
    - (사용자가 Item에 싫어요를 누름, 최신 Item의 Score가 증가함)

## Candidate Generation
---
Query가 주어졌을 때 시스템은 연관된 candidate의 set을 만든다.
1. Content-based filtering: 사용자가 좋아하는 것과 유사한 item을 추천하기 위해 item 간의 similarity를 활용함
    - 사용자 A가 두 개의 `귀여운 고양이 영상`을 시청한 경우,
    - 시스템은 `귀여운 동물 영상`을 A에게 추천
2. Collaborative filtering: 추천을 위해 query와 item 간 similarity를 동시에 활용함
    - 사용자 A와 B가 서로 유사하고 B가 `비디오 1`에 좋아요를 누른 경우,
    - (A는 `비디오 1`과 유사한 비디오를 본 적이 없어도) 시스템은 A에게 `비디오 1`을 추천

임베딩 공간
- 위의 두 가지 방식 공통적으로, 각 item과 query를 임베딩 공간 내 벡터로 맵핑함
- 임베딩 공간은 코퍼스 크기 대비 low-dimension이며, item 또는 query set의 latent structure를 갖는다
    - 사용자 A가 YouTube에서 주로 시청한 비디오들은 임베딩 공간 내에서 서로 가까이 위치
- 얼마나 가까운지는 **Similarity measure** (유사도 측정)에 의해 정의됨.

유사도 측정
- 임베딩 쌍에 대한 유사도 값을 반환하는 함수 $s: E\times E\rightarrow R$
- Query 임베딩 $q\in E$가 주어졌을 때, 시스템은 $q$와 가까운 item 임베딩 $x\in E$과의 유사도 $s(q, x)$를 계산

유사도 측정법
1. Cosine: $s(q, x) = \cos(q, x)$
2. Dot product: $s(q, x) = <q, x> = \sum_{i=1}^{d}g_{i}x_{i}=\vert\vert x\vert\vert \vert\vert q\vert\vert\cos(g,x)$
    - 임베딩 $q, x$가 normalized된 경우 ($\vert\vert q\vert\vert = \vert\vert x\vert\vert = 1$), $\cos(q, x) = <q, x>$
3. Euclidean distance: $s(q, x) = \vert\vert q-x\vert\vert = \Big[ \sum_{i=1}^{d} (g_{i} - x_{i})^{2} \Big]^{\frac{1}{2}}$


Dot product 방식: item의 embedding norm이 클 수록 유사도는 커지고, 추천도 더 많이 됨 (임베딩의 norm에 민감)
1. 학습 데이터셋에서 자주 나타나는 item (예 - 인기 있는 YouTube 비디오)는 보통 large norm을 갖는다
    - 인기 정보를 찾는 것이 목적이라면 dot product가 적합
    - 그러나 인기 있는 item만 추천 대상에 오를 수 있다
    - norm의 영향을 줄이기 위해 변형된 유사도 측정법을 사용할 수 있다
        - $s(q, x)=\vert\vert q\vert\vert^{\alpha} \vert\vert x\vert\vert^{\alpha}\cos(q, x) \text{ where }\alpha\in(0, 1)$
2. 거의 발생되지 않는 item은 학습 과정동안 자주 update되지 않을 것
    - 해당 item이 large norm으로 초기화되는 경우, 시스템은 실제로 더 관련있는 item보다도 이 item만 추천할 것
    - 임베딩 초기화와 적합한 regularization 과정이 중요하다 
