---
layout: post
title:  "Transformers4Rec"
parent: Paper
grand_parent: Study
# nav_order: 2
permalink: /docs/study/paper/2023-04-22-t4r
date:   2023-04-22 23:00:00 +0900
---
# Bridging the Gap between NLP and Sequential/Session-Based Recommendation
{: .no_toc }

## 목차
{: .no_toc .text-delta }

1. TOC
{:toc}

## Transformers4Rec이란

![](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/_images/nlp_x_recsys.png?raw=true)

HuggingFace의 Transformer 라이브러리 위에 Sequential/Session-based RecSys를 구현한 오픈소스 라이브러리

## Architecture

![](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/_images/pipeline.png?raw=true)

> Sequential/Session-based Recommendation이 언어 모델과 다른 점
> 1. 추가적인 정보가 포함된다
> 2. 평가 지표로 Ranking의 개념이 사용된다
> 3. Concept drift가 강하게 발생한다  
> 기존 모델이 표현할 수 없는 데이터의 등장 (Target variable의 통계적 특징이 변화)

### Data preprocessing and Feature engineering
NVIDIA NVTabular 라이브러리
- GPU 가속을 활용한 전처리를 제공한다
- Parquet 파일을 바로 GPU 메모리에 올리는 NVTabular Dataloader를 활용하여 모델의 학습 및 평가를 빠르게 한다.

### Model training and evaluation
HuggingFace에서 제공하는 Trainer class를 상속받아 `predict(), evaluate()` 메서드를 오버라이딩한다.

### Meta-Architecture
![](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/main/_images/transformers4rec_metaarchitecture.png?raw=true)

1. Sparse (Categorical) or continuous (Numerical) feature와 같은 Input feature는 `Feature Processing Module`에 의해 Normalize and Combine되어 `Interaction embedding`을 생성한다.
2. Interaction embedding으로 구성된 시퀀스는 `Sequence Masking Module`에 의해 Masking되어 `Sequence Processing Module`의 입력으로 들어간다
3. 시퀀스 내 각 Position에 대한 Output vector는 Projection을 통해 Sequence embedding을 만든다.
4. `Prediction head module`은 Item-level (Item 추천) 또는 sequence-level (분류) prediction 등 다양한 Task에 적용된다.

> NLP와 마찬가지로 RecSys에서도 Item ID는 Interaction을 표현하기 위한 가장 중요한 요소나,  
> `Item 메타데이터나 User context 다른 Feature는 추가적인 정보를 제공한다.`

Input feature representation
- `Categorical feature` $\rightarrow$ Categorical embedding (Cardinality에 비례하거나 고정 크기)
- `Continuous numerical feature` $\rightarrow$ Scalar 또는 Soft One-Hot Encoding

|Symbol|Meaning|
|---|---|
|$s^{(u)}$|Session or sequence of user $u$|
|$x^{(u)}=x_{1:n_{u}}^{(u)}$|a sequence of $n_{u}$ items|
|$f^{(u)}=\{f_{i, 1:n_{u}}^{(u)}: i \in 1, ..., I \}$|$I$ feature sequences|

Input feature aggregation

|Merge method|Expression|
|---|---|
|Concatenation merge|$m_k=concat(x_k^{(u)}, f_{1,k}^{(u)},...,f_{I,k}^{(u)})$|
|Element-wise merge|$m_k=x_k^{(u)}\odot[1+f_{1,k}^{(u)}+...+f_{I,k}^{(u)}]$|

> Item ID에 대한 Embedding과 모든 Additional feature가 같은 Dimension을 가져야 한다.

## Question
> Q3: 추천 성능 향상을 위해, Transformer 구조에 적합하게 Additional feature를 활용하는 방법이 있는가?

1. Concatenation merge
2. __Concatenation merge w/ continuous features (Soft One-Hot Encoding)__
    - SOHE 방식은 Continuous feature와 Categorical feature를 결합하여 효과적인 Representation으로 제공한다.
3. Element-wise merge
