---
title: "CNN"
layout: post
parent: Introduction to AI
grand_parent: Coursework
nav_order: 4
date:   2022-02-27 10:41:00 +0900
---
# Convolutional Neural Networks
{: .no_toc }

<details open markdown="block">
  <summary>
    목차
  </summary>
  {: .text-delta }
1. TOC
{:toc}
</details>

## Visual Recognition
---
`시각 데이터를 이해한다`
1. Concept의 존재 여부를 확인한다
2. Object의 위치를 파악한다
3. Concept간의 관계를 확인한다
4. Scene 내 Context를 이해한다

Challenges: 다양한 appearance variation을 처리해야 한다
- Viewpoint (보는 방향), Scale (크기), Deformation (다른 자세), Occlusion, Illumination (빛의 조건), Background clutter (호랑이 가죽 위에 있는 호랑이), Intra-class variation (의자의 다양한 종류)
- $\therefore$ Variation으로부터 invariant한 universal feature를 설계하는 것은 매우 어렵다!

## DNN for high-dimensional data
---

![cnn_1](../../../assets/images/2022-02-27-image-1.png){:style="display:block; margin-left:auto; margin-right:auto; width: 450px"}

MLP (Multi-layer perceptron): `linear layer와 비선형 활성화 함수`의 stack

### MLP의 문제점
파라미터가 너무 많이 필요하다
- 현재 layer의 모든 neuron을 다음 layer의 모든 neuron과 연결
- 입력값의 크기 (dimension)가 클수록 신경망의 깊이와 너비 또한 증가
- 예) 28*28 이미지, 3-layer MLP (784-2048-1024-10)
    - 필요 파라미터 수: `784*2048 + 2048 + 2048*1024 + 1024 + 1024*10 + 10` = 3,716,106개
- GPU 메모리 용량을 초과한다..
    - 연산적으로 고비용 (Computationally expensive)
    - forward/backward propagation 과정에서 엄청난 연산이 요구됨
    - Overfitting이 발생할 수 있다 (파라미터의 수가 학습 데이터 수보다 지나치게 많은 경우 흔히 발생)

![cnn_2](../../../assets/images/2022-02-27-image-2.png){:style="display:block; margin-left:auto; margin-right:auto; width: 450px"}

Fully-connected layer의 비효율성
- primitive (복잡한 대상을 표현할 때 사용되는 기초 요소)
    - `9`는 `o`과 `|`의 조합, `8`은 `o` 두 개의 조합, ... 
- 같은 primitive 라도 모든 위치에 대해서 모델이 인식하도록 파라미터를 학습시켜야 함!
    - 파라미터의 중복성 (Huge redundancy)
    - 엄청나게 큰 신경망을 필요로 함

### Filtering
값의 배열 Filter를 이용하여 모든 이미지 내 위치에서 weighted average를 계산한다

1) 4*4 filter가 주어진다

$\begin{bmatrix}
.0 & 1. & 1.& .0\newline
.0 & 1. & 1.& .0\newline
.0 & 1. & 1.& .0\newline
.0 & .9 & .9& .0\newline
\end{bmatrix}$

2) filter와 같은 이미지 영역에 대해 element-wise multiplication and average 결과를 저장한다

![cnn_3](../../../assets/images/2022-02-27-image-3.png){:style="display:block; margin-left:auto; margin-right:auto; width: 250px"}

3) 결과
- Filter는 특정한 시각적 primitive (`o`이나 `ㅣ`)에 대한 neuron을 활성화시키는 파라미터이다.
- filter는 object가 어느 위치에 있든 처리할 수 있다
- Filtering은 translation invariant


![cnn_4](../../../assets/images/2022-02-27-image-4.png){:style="display:block; margin-left:auto; margin-right:auto; width: 450px"}

## CNN
---

![cnn_5](../../../assets/images/2022-02-27-image-5.png){:style="display:block; margin-left:auto; margin-right:auto; width: 450px"}

Main idea: filter를 parameterize한다
1. Input (`32*32*3` 크기의 이미지)과 filter (`5*5*3`)
2. Filter를 image에 convolve한다
    - convolve (이미지에 spatial하게 filter를 slide하면서 dot product 결과를 저장한다)
3. Activation map (연산 결과)을 얻는다
    - map size는 `28*28*1`이다 (가로/세로는 `32-5+1=28`, 높이는 `1`)
    - 6개의 (동일 사이즈) filter를 적용하면, 6개의 activation map을 얻는다
    - stacked map은 `28*28*6` 사이즈의 새로운 이미지이다

![cnn_6](../../../assets/images/2022-02-27-image-6.png){:style="display:block; margin-left:auto; margin-right:auto; width: 450px"}

Convolution layer의 operation 종류
- Naive (위에서 했던 방식)
- Padding (이미지 boundary에 특정 value를 추가한다)
- Stride (N개의 픽셀 간격으로 sparse한 convolution)

Convolution layer의 arithmetic
- Input 크기 `N*N*C` (가로/세로/채널 수)
- Convolution `K, S, P, D` (#Kernel/Stride/Padding/#Filter)
- Output 크기 `N'*N'*C'` (가로/세로/채널 수)
    - $N'=\frac{N-K+2P}{S}+1$
    - $C'=D$

Conv layer와 Fully-connected layer
- FC layer 
    - 모든 node는 다음 layer의 모든 node에 연결)
- Conv layer 
    - 모든 node는 locally connected (kernel 크기에 의해 neighborhood 결정)
    - weight는 다른 spatial location을 따라 공유

![cnn_7](../../../assets/images/2022-02-27-image-7.png){:style="display:block; margin-left:auto; margin-right:auto; width: 450px"}

Receptive field (field of view)
- 특정 layer의 단위 activation unit가 다루는 이미지 영역 (image region covered)으로, $R_{out}=R_{in}+(K-1)\times S$

||Input layer|1st layer|2nd layer|3rd layer|
|---|---|---|---|---|
|$R_{out}$|1|`1+(7-1)*1=7`$\rightarrow$`7*7`|`7+(3-1)*1=9`$\rightarrow$`9*9`|`9+(3-1)*2=11`$\rightarrow$`11*11`|

![cnn_8](../../../assets/images/2022-02-27-image-8.png){:style="display:block; margin-left:auto; margin-right:auto; width: 300px"}

Spatial pooling layer
- Convolution은 local information만 다루지만, 결국은 전체 이미지 정보를 기반으로 하는 예측을 수행해야 함
- pooling window는 공간적으로 추상화된 정보를 포함 (spatially abstract information)하며, 각 채널마다 independent하게 적용된다
    1. Max-pooling (pooling window 내 최댓값을 계산)
    2. Avg-pooling (pooling window 내 평균값을 계산)

## Summary
---

![cnn_9](../../../assets/images/2022-02-27-image-9.png){:style="display:block; margin-left:auto; margin-right:auto; width: 500px"}

Convolution Neural Network
- Convolutional layer (Convolution, 비선형 활성화 함수, pooling 과정의 반복)
    - Convolution을 사용하는 이유: 효율적인 parameterization (local connection, weight sharing)
- Fully-conneceted layer (linear layer와 비선형 활성화 함수 과정의 반복)
- Output layer (예측값에 softmax 함수를 적용하여 정규화한 값으로 label을 결정)








