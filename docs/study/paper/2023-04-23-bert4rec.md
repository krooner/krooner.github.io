---
layout: post
title:  "BERT4Rec"
parent: Paper
grand_parent: Study
# nav_order: 2
permalink: /docs/study/paper/2023-04-23-bert4rec
date:   2023-04-23 23:00:00 +0900
---
# Sequential Recommendation with BERT
{: .no_toc }

## 목차
{: .no_toc .text-delta }

1. TOC
{:toc}

## 추천 시스템의 목표
`사용자의 과거 행동 기록으로부터, 사용자의 동적인 선호 및 관심을 모델링`하는 것

사용자의 관심사를 정확히 특징짓기 위해 고려해야할 점
1. 사용자의 현재 관심사는 동적이며, 진화한다.
2. 그리고 과거 행동에 영향을 받는다; `닌텐도를 구매한 사용자는 이후 컨트롤러를 주문했다`

## 순차적 신경망
- 사용자의 Interaction 기록을 Vector로 Encoding
- Left-to-right unidirectional 학습을 진행
    - Unidirectional 모델은 사용자 행동 시퀀스에 대한 Hidden representation을 잘 학습하지 못한다.  
    `각 Item이 오직 Previous Item 정보로만 Encoding되므로`
    - 엄격히 순서가 정해진 (Rigidly Ordered) 시퀀스를 가정하나 현실 데이터는 그렇지 않다.

## BERT4Rec

![](https://recbole.io/docs/_images/bert4rec.png)

Bidirectional Self-attention을 적용하여 양쪽에서의 Context를 포함할 수 있다.

|Symbol|Meaning|
|---|---|
|$U=\{u_{1}, u_{2}, u_{3}, ... , u_{\|U\|}\}$|사용자 집합|
|$V=\{v_{1}, v_{2}, ..., v_{\|V\|}\}$|Item 집합|
|$S_{u}=[v_{1}^{(u)}, v_{2}^{(u)}, ..., v_{n_{u}}^{(u)}]$|사용자 $u$의 (시간순 정렬된) Interaction 시퀀스|
|$v_{t}^{u}\in V$|사용자 $u$가 Timestep $t$에 Interact한 Item|
|$P(v_{n_{u}+1}^{u}=v\|S_{u})$|사용자에 대한 시퀀스가 주어졌을 때 다음 Timestep에 특정 Item을 Interact할 확률|



### Transformer Layer
모든 위치에 대해 Attention function을 계산하기 위해
- MHA (Multi-Head Self-attention)
    1. $H^{l}$를 $h$ Subspace에 Linear Projection (Learnable, different)
    2. Parallel하게 $h$ Attention function을 적용
    3. Concatenation $\rightarrow$ Projection $\rightarrow$ `Output`
- Position-wise FFN (Feedforward Network)
    - Nonlinearity를 부여하며 다른 Dimension에서의 Interaction을 제공

|Symbol|Meaning|
|---|---|
|$t, d$|각각 `입력 시퀀스 길이`와 `Hidden representation의 차원`|
|$h_{i}^{l}\in \R^{d}$|Layer $l$에서, Position $i$에 대한 Hidden representation|
|$H^{l}\in \R^{t\times d}$|Layer $l$에서의 Stacked hidden representation|
|$\text{MHA}(H^{l})=[\text{head}_{1}\|\text{head}_{2}\|...\|\text{head}_{h}]W^{o}$|Output of MHA|
|$\text{head}_{i}=\text{Attention}(H^{l}W_{i}^{Q}, H^{l}W_{i}^{K}, H^{l}W_{i}^{V})$|Linear Projection and Attention of each head|
|$W_{i}^{Q}\in \R^{d\times\frac{d}{h}}, W_{i}^{K}\in \R^{d\times\frac{d}{h}}, W_{i}^{V}\in \R^{d\times\frac{d}{h}}, W_{i}^{O}\in \R^{d\times d}$|Projection parameters for $Q, K, V$, and `Output` (Linear, Learnable, not shared across layers)|
|$\text{Attention}(Q, K, V)=\text{softmax}(\frac{QK^{\top}}{\sqrt{\frac{d}{h}}})V$|Scaled dot-product attention|
|$\text{PFFN}(H^{l})=[\text{FFN}(h_{1}^{l})^{\top}\|...\|\text{FFN}(h_{t}^{l})^{\top}]^{\top}$|Position-wise Feedforward Network|
|$\text{FFN}(x)=\text{GELU}(xW^{(1)}+b^{(1)})W^{(2)}+b^{(2)}$|Feedforward Network|
|$\text{GELU}=x\Phi(x)$|Gaussian Error Linear Unit; $\Phi(x)=\text{cdf of std. gaussian distribution}$|
|$W^{(1)}\in\R^{d\times 4d}, b^{(1)}\in\R^{4d}, W^{(2)}\in\R^{4d\times d}, b^{(2)}\in\R^{d}$|Parameters|

$L$개의 Bidirectional Transformer Layer가 Stacking된 구조
- 각 Layer에서는 반복적으로, 모든 Position에 대한 Representation을 수정  
(이전 Layer에서 계산된 모든 정보를 병렬적으로 교환)
- Token간 Distance와 무관하게 Dependency를 학습할 수 있다: `Global receptive field`

$H^{l}=\text{Trm}(H^{l-1}) \quad \forall i\in [1,...,L]\\\text{Trm}(H^{l-1})=\text{LN}(A^{l-1}+\text{Dropout}(\text{PFFN}(A^{l-1})))\\ A^{l-1}=\text{LN}(H^{l-1}+\text{Dropout}(\text{MHA}(H^{l-1})))$

### Embedding Layer
입력 시퀀스의 순서 정보를 부여하기 위해,  
Transformer Layer 스택 최하단에 있는 Item Embedding에 Positional Embedding을 합한다.

|Symbol|Meaning|
|---|---|
|$h_{i}^{0}=v_{1}+p_{i}$|Item $v_i$에 대한 Input representation|
|$\textbf{v}_i\in \textbf{E}$|Item $v_i$에 대한 Embedding ($d$-dimensional)|
|$\textbf{p}_i\in \textbf{P}$|Position index $i$에 대한 Position Embedding ($d$-dimensional)|
|$\textbf{P}\in \R^{N\times d}$|Positional Embedding Matrix|
|$N$|Maximum sentence length|

$t>N$인 경우 $[v_1^{u}, ..., v_t^{u}]\rightarrow [v_{t-N+1}^{u},...,v_{t}^{u}]$
- ~~처음부터가 아닌~~ 끝에서 $N$개의 Item만 가져온다

### Output Layer
$L$개의 Layer를 거쳐, 입력 시퀀스의 모든 Item에 대한 Final output $H^{L}$를 얻게 된다  
Timestep $t$에 대한 Item $v_t$를 Masking했을 때, $h_t^{L}$를 기반으로 $v_t$를 예측한다

|Symbol|Meaning|
|---|---|
|$P(v_t=v)=\text{softmax}(\text{GELU}(h_t^{L}W^{P}+b^{P})E^{\top}+b^{O})$|Output distribution over target items|
|$E\in \R^{\|V\|\times d}$|Embedding matrix for the item set $V$|

### Cloze Task
~~순차적으로 다음 Item을 예측하는 것이 아님~~

> 양방향에 대한 Joint conditioning의 경우 Information leak가 발생할 수 있다.  
(간접적으로 `target item`에 대한 정보를 알게 되므로)  

학습
1. 임의로 Item을 Masking한다: `dog` $\rightarrow$ `[MASK]`
2. 주위 Context를 기반으로 Masking Item이 무엇이었는지 예측한다

|Symbol|Meaning|
|---|---|
|$Loss=\frac{1}{\|S_{u}^{m}\|}\sum_{v_m\in S_u^{m}}-\log P(v_m =v_{m}^{\ast}\|S_{u}^{`})$|the loss for each masked input $S_u^{`}$|
|$S_u^{`}$|the masked version of user behavior history $S_u$|
|$S_u^{m}$|the set of random masked items in $S_u^{`}$|
|$v_m^{\ast}$|the true item for the masked item $v_m$|


추론
- 입력 시퀀스 마지막에 `[MASK]` 토큰을 삽입하여 나타나는 Final hidden vector를 기반으로 추론



