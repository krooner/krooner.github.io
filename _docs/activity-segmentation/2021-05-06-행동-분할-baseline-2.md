---
layout: post
title:  "실시간 행동 분할 논문 2"
date:   2021-05-06 16:00:00 +0900
parent: Activity Segmentation
nav_order: 3
---

# Paper
> _S. Aminikhanghahi, T. Wang and D. J. Cook, **"Real-Time Change Point Detection with Application to Smart Home Time Series Data,"** in IEEE Transactions on Knowledge and Data Engineering, vol. 31, no. 5, pp. 1010-1023, 1 May 2019, doi: 10.1109/TKDE.2018.2850347._

# Target Problem
> * ***(near) Real-time, Unsupervised*** Change Point Detection Algorithm을 제안함


# Why is it important
>* CPD를 Real-time application으로 활용하려면, **새로 들어온 event가 Change Point인지 ASAP하게 판단해야 함**
  - e.g. **sensor-based smart home data**를 실시간으로 받아올 때 **latest event가 change point이면, 여기서 잘린 stream은 하나의 Activity로 표현됨**
  - 그러나 current event가 change point인지 알려면, **future data** 또한 필요하다; <u>*"near" real-time*</u>
  
>* Real-time and Unsupervised CPD = <u>*Direct density-ratio estimation을 제안하는 이유*</u>
>>  - **direct density-ratio estimation**을 활용; KLIEP, RuLSIF, ...
        - SEP는 기존 DRE 알고리즘보다 더 sensitive함 = **약간의 change에도 relatively high dissimilarity score**
        - 두 연속적인 windows의 확률분포비율(probability density ratio)를 추정함; <u>"두 window가 같은 상태에 있다면, 둘의 확률 분포는 동일하다"</u>는 것을 가정

# Definitions
> * **Time-series data stream**: infinite sequence of *d*-dimensional elements
* **Data distributions**
  - Probability density function of Subset *B*
  - Probability of random variable *X* (in subset *B*)
* ** Change Point *t* ** : event *t*의 "이전" 그리고 "이후" sliding-windows로부터 만들어진 pdf가 서로 다른 경우
>
>> - 가설 검증
        - *H0* : event *t*에서는 어떠한 변화도 없다.
        - *Ha* : 두 개의 연속적인 sliding-windows의 각 pdf가 서로 다른 경우가 존재한다.
* ** *n* real-time**: event *t*가 change point인지 판단하기 위해선, event *t* 이후로 *n*개의 future event가 더 필요하다.

# Existing Works of CPD
> 1. *Supervised* with labelled training data
>>    - Multi-class classifier
          - **매우 많은 양의, 다양한 training data를 필요로 함; 각 State (e.g. Activity) 에 해당하는 data + 모든 Transition data**
>>    - Binary classifier
          - **가능한 Transition type이 많아질수록 학습의 Complexity가 급상승**
>>    - Virtual Classifier (VC)
          - 모든 two consecutive window pair에서 first window에는 +1, second window에는 -1 (hypothetical label)을 부여
          - VC를 decision tree같은 rule-based model로 학습시킴 (VC는 각 pair마다 존재)
          - Change Point를 감지하는 경우, pair of samples를 가지고 VC를 재학습시킴
          - VC에 있는 dominant feature가 state change를 규정

> 2. *Unsupervised* with statistical feature of data
  **Promising한 이유 = 모든 change cases에 대한 prior knowledge 학습 없이, 다양한 situation에 대응할 수 있음**
>  
>>    - **Subspace Modeling**: data를 state space로 표현하고, change point를 state space 내 distance로 감지함
      - Subspace Identification (SI): 각 sliding-window에서 생성된 state space model에서 matrix를 생성한 후, subspace 간 gap을 계산
      - Singular Spectrum Transformation (SST): 두 windows 각각 trajectory matrix에서 singular spectrum을 비교
>
>>    - **Probabilistic Methods**: 이전 Change Point Candidate event에서부터 얻은 data와 새로운 window의 확률 분포를 추정
      - Bayesian CPD: 현재 event의 run-length **r** (elapsed time from prev CP candidate)를 추정, 다음 event의 **r'**: 0 (현재 event가 CP로 감지됨) 또는 **r+1** (otherwise)
      - Gaussian Process (GP): data를 noisy Gaussian distribution function value로 표현, predicted value와 actual value를 비교함
>
>>    - **Clustering Methods**: data를 클러스터링 한 다음, Cluster state feature의 difference를 계산
      - SWAB (Sliding Window and Bottom-up): 각 event를 separate sequence로 본 다음 merge해서 subsequence로 만듦 + buffer에 있는 change point data를 빼내고 다음 data를 넣음
      - MDL-based: bottom-up greedy search: cluster 수를 정의하지 않아도 됨
      - Shaplet-based: greedy search + time-series shape을 기반으로 클러스터링
>
>>    - **Kernel-based Methods**: data를 high-dimensional feature space에 맵핑하고, 각 feature의 homogeneity를 비교함
>>    - **Graph-based Methods**: data를 각 node로 하는 graph로 표현한 뒤 two-sample statistical test로 detection

> ** Likelihood-ratio Methods**
>>- Density ratio CPD: Unsupervised, Near-real time, (Good Performance)
  (Assumption = 두 연속적인 windows의 확률 분포가 동일하다는 건 같은 state에 있다는 것, Otherwise, state changes)
  - Cumulative Sum (CUSUM)
      - input의 특정 target에 상대적인 deviation을 누적시키고, 누적 값이 threshold를 초과했을 때가 Change point.
  - Change Finder (CF)
      - pre-defined parametric model을 사용하므로 less flexible
>
>>* **Direct density-ratio estimation**: windows 각각에 대한 확률-밀도추정없이, 바로 확률밀도"비율"을 추정하는 non-parametric Gaussian Kernel model 
(Related Work 1과 동일한 Category)
    - two consecutive windows: **w(t-1), w(t)** with length ***n***
    - corresponded probability densities: **fw(t-1), fw(t)**
    - ***dissimilarity measure (dm)***: 두 windows 간 change point의 존재 여부를 결정하기 위한 difference measurement
  - **KLIEP**: KL-divergence (KLDiv)를 dm으로 두고 density ratio를 추정
  - **uLSIF**: Pearson-divergence (PEDiv) 를 dm으로 두고 추정
  - **RuLSIF**: uLSIF의 문제 (second window 분포에 따라 dm 값이 기하급수적으로 커질 수 있음) 개선을 위해, alpha-relative PEDiv를 사용
      
    
# Methods (SEP)
> * Goal: data 내 미세한 변화에도 매우 sensitive한 Change Point Score를 적용하자
  - Separation Distance Metric을 사용함
  - 알고리즘 설명은 생략
  
> * Process
  1. Data Collection
  2. Sliding event window (30 events)
  3. Event feature extraction: each feature corresponds to each event
  4. feature window (2 features)
  5. Applying SEP and detect change points
        - threshold = 0.1

# Evaluation
> 1. Artificial Dataset: 전반적으로 **SEP > RuLSIF > uLSIF** 순으로 좋은 ATD Performance를 보임
    
> 2. Smart Home
    - Description
      - Single-resident
      - Motion and Door Sensor (Discrete Binary)
      - 6 apartment datasets
      - 12 Activities (11 pre-defined + "Other" Activity)
    - Performance
      - (True Positive Rate과 False Positive Rate 간 ROC-AUC Curve, Mean Absolute Error 모두) 역시 **SEP > RuLSIF > uLSIF**
      
> 3. Other Real-world Dataset: **SEP의 TPR도 높지만, FPR도 가장 높음**
    - ***FPR이 높다 = Wrong Detection이 많다 = Segmentation이 제대로 되기 어렵다.***
    - 단순히 FP/(FP+TN) 보다는 FP를 P(=FN+TP)와 비교해야하지 않을까요?
  
# Discussion
>* 논문에서 설명한 Improvement 또는 Limitation
1. 이전 Window가 현재 이벤트의 Dissimilarity Score에 미치는 영향 (information)을 고려하면 개선할 수 있지 않을까?
2. **Threshold Selection이 Performance에 직접적으로 영향을 준다**
3. **SEP의 Computational Cost가 너무 크다; computational efficiency를 요한다.**
    - 2-real time 알고리즘이라고 말하긴 했지만, 사실 event 하나에 대해 SEP를 수행하는 것도 Replication 기준 1초 내외가 걸림
    - 수십-수백만 이벤트에 대해 SEP를 적용하면 Calculation Delay가 너무 커서 Real-time Application을 시도할 수 없음

>* Replication을 하면서 생긴 의문점
  - **Cross-validation은 Target Dissimilarity Measure를 최소로 하는 Parameter를 정함**.
   그러므로 기존 direct density-ratio based CPD (uLSIF) 와는 다른 objective function을 써야한다고 생각함
  - 근데 왜 이 논문은 그런 과정을 쏙 빼고, "Cross-validation으로 구하면 된다" 라고 하고 uLSIF cross-validation에 대한 Reference를 걸고 그냥 넘어가지?
   이렇게 보면 그냥 동일한 Loss function을 사용한 것으로 볼 수 밖에 없음. **과연 이렇게 해석하는 것이 맞는 것인가**
  - Separation distance도 **max(0, 0.5-k), k>0** 로 뒀으면서, 그래프를 보면 또 [0, 1] 을 Y값으로 한다.
  - 이 알고리즘을 활용한 Activity Segmentation 논문을 Baseline으로 삼고 Replication을 하고 있는데, 이런 점이 헷갈려서 저자에게 메일을 보냈는데 읽씹당했다. 너무하다,,
  - 잘 써놓은 건데 내가 멍청한건가 싶기도 하다.