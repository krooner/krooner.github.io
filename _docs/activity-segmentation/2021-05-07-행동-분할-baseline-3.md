---
layout: post
title:  "실시간 행동 분할 논문 3"
date:   2021-05-07 16:00:00 +0900
parent: Activity Segmentation
nav_order: 4
---


# Paper
> *Samaneh Aminikhanghahi, Diane J. Cook, **Enhancing activity recognition using CPD-based activity segmentation**, Pervasive and Mobile Computing, Volume 53, 2019, Pages 75-89, ISSN 1574-1192, https://doi.org/10.1016/j.pmcj.2019.01.004.*

# Target Problem
> 
* (near) **Real-time Activity Transition Detection (ATD)**
* Ultimate goal: "Improving" **Human Activity Recognition (HAR)**
>
>> **Real-time ATD**으로 얻은 Information (Feature)를 활용하여 **HAR의 Performance를 향상**

# Why is it important
>
* *Human Activity Learning*: Activity Recognition, Detection, **Segmentation**, Forecasting
* *Activity Segmentation*: <u>**pre-segmented data, Fixed-size Sliding Window** 또는 **Activity마다 window-size를 정함**</u>
  - **Limitation**
    1. 전체 dataset을 사용하는 **batch, offline** 방식; real-time application에 부적합함
    2. Sliding window는 online 방식으로 적용할 수 있으나, **Optimal window-size를 찾는 것이 매우 어려움**
* Change Points (Events)
  - **Activity의 Boundary**를 알면 Activity duration, start/end time 등 **Activity의 특징을 잘 반영하는 Feature**를 활용하여 **Recognition 성능을 개선할 수 있음**
>  
>> **Transition-aware Activity Segmentation**을 제시함


# Related Works
>
* **기존 Activity Segmentation**은 Video 또는 Wearable data (Accelrometer, gyroscope, ...)를 다룸;
  - IoT의 등장으로 **Sensor-based stream segmentation** 문제가 새로 등장함
>
>>
* Previous Sensor Segmentation
    - **Threshold**를 기준으로 Static Activity에서 Movement Activity로의 변화 감지
    - Wavelet Decomposition Model, Crowd-sourcing, LSTM, Two-step Supervised Classifier (Neural Network and HMM), ...
  - **Limitation**
    1. Supervised with Scripted Environment: 사용자들은 정해진 instruction에 따라서만 행동하며 data를 생성함
      **즉, real-world 환경에서의 sensor data와는 차이가 있다.**
    2. Real-world에서의 stream은 다른 activity 간 boundary를 정의하기 매우 어렵다
      **Unsupervised approach가 필요하다**     
>
>>
* **Unsupervised Approaches**
  - SVM + Association Rule Mining:
    - SVM은 raw sensor events로 Activity Recognition을 하거나, boundary information을 찾음
    - ARM은 boundary recognition 결과를 확인함
  - Probabilistic SVM
  - **Three** different Decision Trees: Transition Activity Detector, Non-transition Activity Classifier, Transition Activity Classifier
  - Multivariate Online Change-detection Algorithm (MOCA): based on statistical values (mean, variance-covariance matrix)
    - **Assumption이자 Limitation**: continuous-valued feature를 사용하며 Data는 Gaussian Distribution을 따름
  - RuLSIF (for ATD) and HMM (for Recognition)
>
> * **Activity Segmentation**은 Recognition에 benefit을 줄 수 있으나, 현재는 **manually segmented 또는 sliding window** 방식을 사용하고 있음
  - 참고로, **Input length에 independent한 RNN Model**이 있지만 **Supervised approach with large amount of data**이므로 PASS
  - ATD에는 Supervised and (RuLSIF-based) Unsupervised classifier가 있는데,
    - Supervised; not appropriate in real-time (sufficient labelled data)
    - <u>***Unsupervised*** approach with (near) real-time = **SEP**</u> (outperforms RuLSIF)

# Definitions
>
* an infinite sequence of sensor events: ***{e1, ... , ei, ...}***; 
  - *event e=<timestamp, sensor, value>*
* activity window: ***{e1, ..., en}*** 
  - extract <u>*feature vector*</u> from window and predict <u>*label*</u> using feature
* Change Point Detection
  - ***pdf from sliding-window before t***
  - ***pdf from sliding-window (immediately) after t***
  - 두 pdf가 sufficient한 difference를 보이는 경우, event (또는 timestamp) t는 change point; 즉 Activity Transition
* Change Point View
  - 현재 event *t*의 **"이전"과 "이후"**, 일정 길이의 sensor events에 대응되는 Feature set
  - CPD 알고리즘은 두 개의 change point views를 서로 비교함
* Activity Segment
  - 두 개의 연속적인 Activity Transition 사이에 위치한 event sequence

# Methods
>
* Process는 1) Data collection - 2) ATD - 3) AR 순으로 진행됨
* Four approaches에 대한 experiments
>
>>
  1. AR-W: 
      - **traditional sliding-window** based AR
      - window > feature > (predicted) label
      - *No Change Point Information*
      - <u>**Limitation**</u>: Optimal Length를 찾아야 한다는 것.
  2. AR-WT: 
      - AR-W + **additional features** from latest detected transition: ATD에서 얻은 information을 활용
      - Feature 중에서 Sensor Occurrence에 Weight을 둠.
        - **Change Point 직후에 발생한 Sensor의 Occurrence에 더 많은 Weight을 추가**
      - 추가 Feature: 
        - Transition 발생 시간, (Transition 이후) 발생한 Event 수, 최고 빈도 센서와 그 위치, Complexity, Activity Label Change
      - <u>**Limitation**</u>: Activity의 시작과 끝을 모름.
  3. AR-SM:
      - AR-W + all event labels between two transitions are defined by the **majority activity label**
      - 새로운 Transition을 감지하면, 이전 Transition부터 지금까지의 모든 event를 통틀어 majority인 label을 두 Transitions 사이의 모든 Event에 부여함
  4. AR-SS
      - Proposed approach; **transition 사이의 event subsequence를 single activity로 정의함**
      - Event 단위로 보는 것이 아니라, Transition 사이의 segment 단위로 봄
      - Expectation
        - 주요 Features에는 More relevant한 정보가 담길 것이다.
        - Activity Duration, dominant sensor and location, ...
>
> * Segmentation with Real-time ATD: 
  - activity에 대한 prior knowledge 없이, **Feature space에서의 data distribution 변화로 transition을 감지**
  - 즉, time-series data의 확률분포 변화를 보는 CPD 알고리즘; ***SEP***
    - non-parametric CPD
    - **two consecutive change point views** 사이의 change score; ***first view에서 next view***로 발생하는 변화    
>
>
* Process of SEP
>
>>
1. fixed-length **sliding window** (30 events)
2. extracted **features** from windows **(for ATD)**
      - **time** feature: day of week, time of day (from latest event in window)
      - **view** feature: window duration, most frequent sensor, complexity (entropy-based), activity change
      - **sensor** feature: occurrences of each sensor event in window, last time each sensor fired
3. **SEP** between **two consecutive change point views**
    - **view size *n* = 2**
    - 여기서 말하는 Window 또는 View는 모두 **Segmentation** 단계에 해당됨: Recognition에 쓰일 Window와 무관함
    - 알고리즘 설명은 생략. 
    - 각 Event에 매겨진 Dissimilarity Score 중, **Threshold (=0.3)** 이상의 local peak value가 최종 Change point candidate
    - 2-real time algorithm: **현재 event t**가 Change Point인지 알기 위해서는 **event *t+1* and *t+2***가 필요하다.
>
* Activity Recognition
  - **Random Forest Classifier** with 100 decision trees



# Evaluation
>
* **29**개의 CASAS Apartment Dataset을 사용함
  - **Single-resident**
  - **Discrete binary sensors (Motion and Door)**
* 실제 Transition Time 기준으로, **+- 10초 내에 Change Point Candidate이 있으면 True Positive** 처리
  - TPR (Median): SEP (0.88), RuLSIF (0.87)
  - FPR (Median): **SEP (0.12)**, RuLSIF (0.19)
* Confusion Matrix (Median of Accuracy and F-measure)
  - AR-W: (0.633, 0.689)
  - AR-WT: (0.671, 0.729)
  - AR-SM: (0.506, 0.606)
  - **AR-SS: (0.681, 0.735)**
  - AR-W과 AR-WT는 complete real-time이지만, **CPD를 적용하는 AR-SM과 AR-SS는 Processing Delay가 발생하므로 real-time이 아닐 수 있음**
* Normalized Edit Distance (Median)
  - Predicted activity sequence가 Actual activity sequence와 얼마나 차이가 나는지 보여주는 지표
  - AR-W (1.0)과 AR-WT (1.1)보다, **CPD를 적용하는 AR-SM (0.4)과 AR-SS (0.3)이 더 낮은 값**을 보임
* Gini Importance Value
  - AR-WT에서 Transition Feature를 추가한 것이 정말 효과가 있었는지 (Random Forest의 Structure를 변화시켰는지)
  - Current Sensor ID > **Transition Event Sensor ID > Weighted Sensor Occurrence** 순으로 Importance가 컸음
    

  
# Discussion
>
* 논문에서 설명하는 Main Problem과 Limitation
  - **Noise**가 Recognition에 영향을 미침
    - Sensor or environmental noise, data collection, incorrect g.t. labelling
  - **Concept Drift**
    - CPD 알고리즘의 Parameter Tuning을 적용했으나, Human behavior는 Dynamic하므로 unseen pattern을 보이는 (학습 안한) data가 있을 수도 있다
    - Drift Detection and Update 방식을 추가하거나, Additional feature 혹은 method를 적용해볼 수도 있다.
  - Change Point, 또는 Transition을 어떻게 정의할까
    - SEP는 Feature Space에서의 Data distribution 변화를 감지하는 Unsupervised 방식이기 때문에, 우리가 이해하는 Transition과는 다른 change를 감지할 수도 있다.

>
* Personal Comments
  - SEP 구현 과정에서 여전히 **View를 어떻게 설정할 것인지에 대한 의문점**이 있다.
    - **2-real time**이라는 것은 곧 **event *t+1* 과 *t+2* 를 현재 event *t*에 대한 CPD에 사용할 것**이라는 말.
    - 그렇다면 **view size *n*=2**라고 했으니, 
      1. **[feature *t*, feature *t+1*] 과 [feature *t+1*, feature *t+2*]** 을 비교한 Score가 event t의 dissimilarity score인가
       - 현재 Implementation에 이렇게 적용하면 계속 Score가 0이 나옴.
      2. **[feature *t-1*, feature *t*] 과 [feature *t+1*, feature *t+2*]** 인가 **(지금은 이 방식대로 사용함)**
      3. **[feature *t-2*, feature *t-1*] 과 [feature *t+1*, feature *t+2*]** 인가
    - 그러나, **Consecutive** Window라는 말과 **Sliding** Window라는 말이 자꾸 헷갈린다
      - "Sliding" window라는 말 자체가 한 칸씩 움직이면서 window를 이동한다는 말 아닌가? 그렇다면 1이 맞는데..
    - 또 하나 드는 의문은 현재 event의 **"이전과 이후"**를 비교한다고 했는데, 그러면 1번이 아니고 2나 3이 말이 되는 것 아닙니까?
      - 예시 하나만 논문에 써줬으면 이런 생고생은 안 하고 있을텐데, 그렇다고 질문 메일을 보내면 대답도 안 해주고,,
      